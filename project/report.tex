\documentclass[sigconf]{acmart}

\input{format/i523}

\graphicspath{ {images/} }

\usepackage{listings}

\lstset{frame=tb,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\begin{document}

\title{Face Detection and Recognition Using Raspberry Pi Robot Car}

\author{Mani Kumar Kagita}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{107 S. Indiana Avenue}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{43017-6221}
}
\email{mkagita@iu.edu}


\begin{abstract}
Face recognition is an exciting and emerging field of computer vision with many  applications to hardware and devices. Using embedded platforms like the Raspberry Pi, a camera module and open source computer vision libraries like OpenCV, purpose is to add face recognition to Robot car and also facial recognition using free developer version of Kairos Facial Recognition software.
In today`s modern world, face recognition playing an important role for the purpose of security and surveillance and hence there is a need for an efficient and cost effective system. So the main goal is to explore the feasibility of implementing Raspberry Pi based facial recognition system using conventional face detection and recognition techniques such as Haarcascade detection and Kairos. An obstacle avoidance Robot car is integrated with Raspberry Pi and a camera module aiming at taking face recognition to a level in which the system can identify the humans who are stuck in buildings during earth quakes.  Raspberry Pi kit provides the system cost effective and easy to use, with high performance.

\end{abstract}

\keywords{Raspberry Pi, Robot Car, Face Recognition, Face Identification, I523, HID319}

\maketitle

\section{Introduction}
An area of application of Computer Vision, one that has always fascinated people, concerns the capability of robots and computers in general to determine, recognize and interact with human counterparts. In this article we will take advantage of the availability of cheap tools for computing and image acquisition, like Raspberry Pi and his dedicated video camera, Camera Pi, and of open source software products for image acquisition and processing, such as OpenCV and SimpleCV, that allow a high level approach to this discipline, and therefore quite a simplified one.

The possibility to locate, within the context of pictures, human beings or their parts like faces, eyes, nose, and so on. This functionality is available in the most advanced photo gallery applications, and it is currently in the implementation phase as for social network applications. Once photos are loaded, the system will scan them to search for people`s faces, will find them out and will give a chance to associate a name. If, by chance, the same person is present in different pictures, he/she is recognized and automatically ''registered'', notwithstanding privacy concerns. This last functionality is the one we previously cited as the one for identification or recognition.

The information age is quickly revolutionizing the way transactions are completed. There is a need for a faster and accurate user identification and authentication method. Face recognition has become one of the most important user identification methods. Literature survey statistics shows that research work in face recognition system is in its booming era, and in the past forty years, the research in this field has increased exponentially. 

The creation of facial biometric data was the first step in creating complete recognition. The second step was being able to match the data to a database of biometrics and associate it with an individual`s identity. The human eye can quickly process facial characteristics, but the human brain can store only a few hundred faces reliably. After a while, we tend to forget people`s names and often need to relearn information about people. Computers, on the other hand, excel at storing and matching data. Facial recognition software has evolved to the point where computers can process an image and match it against a database of millions of people in seconds.

Law enforcement has led the way with the development of facial recognition systems that can identify criminals against a watch list in real-time. If you`ve traveled through an airport recently, chances are, your facial biometric data has been captured and matched against a watch list.

Having your biometric data stored in a database has raised privacy concerns. Storing biometric data without consent has been a topic of discussion and debate for privacy groups for years and, in some cases, had led to the creation of policies to protect a person’s identity. In addition to privacy concerns, there are also fraud concerns. Having your facial fingerprint matched to what is known as metadata (name, address, and Social Security number, for example) is a major identity theft risk. In order to combat this risk, software vendors have created biometric encryption algorithms to encrypt the data within the database and also provide an almost unbreakable link between the biometric data and the metadata.

\section{Face Detection}
The definition of face detection refers to computer technology that is able to identify the presence of people`s faces within digital images. In order to work, face detection applications use machine learning and formulas known as algorithms to detecting human faces within larger images. These larger images might contain numerous objects that aren`t faces such as landscapes, buildings and other parts of humans (e.g. legs, shoulders and arms).

Face detection is a broader term than face recognition. Face detection just means that a system is able to identify that there is a human face present in an image or video. Face detection has several applications, only one of which is facial recognition. Face detection can also be used to auto focus cameras. And it can be used to count how many people have entered a particular area. It can even be used for marketing purposes. For example, advertisements can be displayed the moment a face is recognized.

\subsection{How Face Detection Works}
While the process is somewhat complex, face detection algorithms often begin by searching for human eyes. Eyes constitute what is known as a valley region and are one of the easiest features to detect. Once eyes are detected, the algorithm might then attempt to detect facial regions including eyebrows, the mouth, nose, nostrils and the iris. Once the algorithm surmises that it has detected a facial region, it can then apply additional tests to validate whether it has, in fact, detected a face.

\section{Face Recognition}
Like all biometrics solutions, face recognition technology measures and matches the unique characteristics for the purposes of identification or authentication. Often leveraging a digital or connected camera, facial recognition software can detect faces in images, quantify their features, and then match them against stored templates in a database.
Face scanning biometric tech is incredibly versatile and this is reflected in its wide range of potential applications.
Face biometrics have the potential to be integrated anywhere you can find a modern camera. Law enforcement agencies the world over use biometric software to scan faces in CCTV footage, as well as to identify persons of interest in the field. Border control deployments use face recognition to verify the identities of travelers. It even has consumer applications.
One of the most important applications of face detection, however, is facial recognition. Face recognition describes a biometric technology that goes way beyond recognizing when a human face is present. It actually attempts to establish whose face it is. The process works using a computer application that captures a digital image of an individual’s face (sometimes taken from a video frame) and compares it to images in a database of stored records. While facial recognition isn`t 100\% accurate, it can very accurately determine when there is a strong chance that an person’s face matches someone in the database.
In the model employed for the extraction of the features from the images, the reference matrices have different shapes, such as the ones that can be seen in figure, that are more suitable for determining the shapes belonging to the human body, like the eyes or the nose. From this comes their denomination of Haar Features, to distinguish them from their original meaning. The same picture shows the shape of the features used by OpenCV and SimpleCV. The presence or not of a Haar feature in a portion of the picture happens by subtracting the median pixel value that are present in the black  mask  portion, from the median value of the pixels that are present in the clear part of the mask. If the difference is above a certain threshold value, the feature is considered as present. The threshold value is determined, for each feature, during the function training, to detect particular objects or parts of the human body. The learning process materializes itself when presenting to the Vision System the highest possible number of images concerning the objects family that we want to identify, and the highest possible number of images that have nothing to share with the object itself. From the amount of data that are studied, the threshold values are calculated, for each of the features that, in the case of OpenCV and SimpleCV, are memorized as a file in .xml format.

\section{Software and Hardware Specifications}
In this project we are using OpenCv in Raspberry pi. This project is used to detect the human Face with the help of OpenCv tool. In order to do object detection with cascade files, you first need cascade files. For the extremely popular tasks, these file already exist.

\subsection{Software Used}

\subsubsection{Raspian OS}
This is the recommended OS for Raspberry Pi. You can also installed other OS from third party. Raspbian OS is debian based OS. We can install it from noobs installer. 
\subsubsection{Putty}
PuTTY is an SSH and telnet client, developed originally by Simon Tatham for the Windows platform. PuTTY is open source software that is available with source code and is developed and supported by a group of volunteers. Here we are using putty for accessing our raspberry pi remotely.

\subsubsection{OpenCV}
OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code. The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects and extract 3D models of objects.

\subsubsection{Python 2 IDE}
Python 2.7.x version Integrated Development Environment is used to compile python program in Raspberry Pi. IDE is a text editor plus terminal combination which is used to work on large projects with complex code bases.

\subsubsection{Kairos Facial Recognition Software}
Kairos is an artificial intelligence company specializing in face recognition. Through computer vision and machine learning, Kairos can recognize faces in videos, photos, and the real-world - making it easier than ever to transform the way your business interacts with people.
\begin{description}
  \item[$\bullet$] Identity 
  \item[$\bullet$] Emotions 
  \item[$\bullet$] Demographics
\end{description}

Kairos navigates the complexities of face analysis technology, so you don’t have to. We offer APIs and SDKs any developer can integrate with ease.

\subsection{Hardware Used}
\subsubsection{Raspberry Pi 3}
This is the latest version of raspberry pi. In this we have inbuilt Bluetooth and wi-fi, unlike previously we have to use Wi-Fi dongle in one of its usb port. There are total 40 pins in RPI3. Of the 40 pins, 26 are GPIO pins and the others are power or ground pins (plus two ID EEPROM pins.) There are 4 USB Port and 1 Ethernet slot, one HDMI port, 1 audio output port and 1 micro usb port and also many other things you can see the diagram on right side. And also we have one micro sd card slot wherein we have to installed the recommended Operating system on micro sd card. There are two ways to interact with your raspberry pi. Either you can interact directly through HDMI port by connecting HDMI to VGA cable, and keyboard and mouse or else you can interact from any system through SSH(Secure Shell)

\subsubsection{Raspberry Pi Camera}
The Raspberry Pi camera module can be used to take high-definition video, as well as stills photographs. It`s easy to use for beginners, but has plenty to offer advanced users if you’re looking to expand your knowledge. There are lots of examples online of people using it for time-lapse, slow-motion and other video cleverness. You can also use the libraries we bundle with the camera to create effects.

\subsubsection{Robot Car Chassis Kit}
The Mechanical design of the Robot car includes hardware such as motor and wheel placement and body setup. Robot car uses two gear-motors attached to wheels and one free wheel for forward, backward, left and right movements. Free wheel ball is placed at rear side of the robot which helps for 360 degrees free movement ~\cite{arduino2015}. L298N DC Stepper Motor Drive controller is used to control the speed and direction of the two gear motor wheels. Ultrasonic sensors are placed at front side of the robot which is capable to detect the objects on its path.



\section{System Architecture}
System Architecture consists of following blocks :
\begin{description}
    \item[$\bullet$] Raspberry Pi

    \item[$\bullet$] Raspberry Pi Camera module 

    \item[$\bullet$] 3 wheel Robot Car kit

    \item[$\bullet$] L298N DC Stepper Motor Drive Controller 

    \item[$\bullet$] 12v and 5v DC batteries
    
\end{description}

The Mechanical design of the Robot car includes hardware such as motor and wheel placement and body setup. Robot car uses two gear-motors attached to wheels and one free wheel for forward, backward, left and right movements. Free wheel ball is placed at rear side of the robot which helps for 360 degrees free movement. L298N DC Stepper Motor Drive controller is used to control the speed and direction of the two gear motor wheels. Ultrasonic sensors are placed at front side of the robot which is capable to detect the objects on its path. Raspberry Pi Camera module is used to monitor the live stream and recognize the face if its detected.

\section{Setup}
\subsection{Connect Raspberry Pi}
This section includes connectivity of Raspberry Pi over Wifi. 
\begin{description}

    \item[$\bullet$] Download Raspbian OS to an SD card with a minimum capacity of 8GB.
    
    \item[$\bullet$] Plug in USB power cable, keyboard, mouse and monitor cables to Raspberry Pi.
    
    \item[$\bullet$] Insert the SD card with Raspbian OS into Pi and boot the system. Once the Pi is booted up, a window will appear with Raspbian operating system. Click on Raspbian and Install.
    
    \item[$\bullet$] When the install process has completed, the Raspberry Pi configuration menu (raspi-config) will load. Here  set the time and date for your region.
    
    \item[$\bullet$] Enable wifi on upper right corner and connect to wifi sid.
\end{description}

\subsection{Connect Raspberry Pi Camera Module}
\begin{description}
    \item[$\bullet$] Install the Raspberry Pi Camera module by inserting the cable into the Raspberry Pi.
    \item[$\bullet$] The cable slots into the connector situated between the Ethernet and HDMI ports, with the silver connectors facing the HDMI port.
    \item[$\bullet$] Boot up your Raspberry Pi and run below commands in command prompt.
    \item[$\bullet$] sudo apt-get install python-pip
    \item[$\bullet$] sudo apt-get install python-dev
    \item[$\bullet$] sudo pip install picamera
    \item[$\bullet$] sudo pip install rpio
    \item[$\bullet$] From the prompt, run ''sudo raspi-config''. 
    \item[$\bullet$] If the ''camera'' option is not listed, you will need to run a few commands to update your Raspberry Pi. Run ''sudo apt-get update'' and ''sudo apt-get upgrade''
\end{description}
\subsubsection{Enable Camera}
For Face Detaction, PiCamera should be enable from Raspberry Pi. Below list of figures shows the detailed steps on how to enable PiCamera from Raspberry Pi.

\begin{figure}[ht!]
  \includegraphics[width=\columnwidth]{images/enablecamera1.jpg}
  \caption{Edit raspi-config file from command line}
\end{figure}

\begin{figure}[ht!]
  \includegraphics[width=\columnwidth]{images/enablecamera2.jpg}
  \caption{Select Camera from the options}
\end{figure}

\begin{figure}[ht!]
  \includegraphics[width=\columnwidth]{images/enablecamera3.jpg}
  \caption{Enable Camera}
\end{figure}

\subsection{Install OpenCV and Required Libraries}
OpenCV computer vision library is used to perform face detection and recognition. For this, first need to install OpenCV dependencies on Raspberry Pi. Below commands needs to be executed. 
\begin{description}
    \item[$\bullet$] sudo apt-get update
    \item[$\bullet$] sudo apt-get upgrade
    \item[$\bullet$] sudo apt-get install build-essential
    \item[$\bullet$] cmake pkg-config python-dev libgtk2.0-dev libgtk2.0 zlib1g-dev libpng-dev libjpeg-dev libtiff-dev libjasper-dev libavcodec-dev swig unzip
    \item[$\bullet$] Select yes for all options and wait for the libraries and dependencies to be installed
\end{description}
Download opencv-2.4.9 zip file to Raspberry Pi. Change the directory and execute cmake command as below.
\begin{description}
    \item[$\bullet$] cd opencv-2.4.9
    \item[$\bullet$] sudo apt-get install build-essential cmake pkg-config
    \item[$\bullet$] sudo apt-get install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev
    \item[$\bullet$] sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev
    \item[$\bullet$] sudo apt-get install python-opencv
    \item[$\bullet$] sudo apt-get install python-matplotlib
    \item[$\bullet$] Latest version of OpenCV is now installed in Raspberry Pi
\end{description}

\subsection{Integration of Raspberry Pi with Robot Car}
Raspberry Pi connected with PiCamera is integrated with Robot car to navigate using webserver. During the navigation, robot car will look for human faces using PiCamera and then detects the face. Once the face is detected, python program will call Kairos facial detection software to identify the person and greet with the name. If the human face is unidentified then robot car will ask human to register their name.

As shown in the figure below, connect a Robot car chassis to raspberry pi and follow the circuit connections.

\begin{figure}[ht!]
  \includegraphics[width=\columnwidth]{images/RaspPi_Robot.jpg}
  \caption{Raspberry Pi Robot Car Integration}
\end{figure}

\begin{description}
    \item[$\bullet$] Motor1A : 16 (GPIO 23 - Pin 16)
    \item[$\bullet$] Motor1B : 18 (GPIO 24 - Pin 18)
    \item[$\bullet$] Motor1Enable : 22 (GPIO 25 - Pin 22)
    \item[$\bullet$] Motor2A : 21 (GPIO 9 - Pin 21)
    \item[$\bullet$] Motor2B : 19 (GPIO 10 - Pin 19)
    \item[$\bullet$] Motor2Enable : 23 (GPIO 11 - Pin 23)
\end{description}

\section{Code Explanation}
\subsection{Face Detection}
\begin{lstlisting}
from picamera.array import PiRGBArray
from picamera import PiCamera
import time
import cv2
import sys
import imutils
from fractions import Fraction
import base64
import requests
import json
import random
import os
\end{lstlisting}


\begin{lstlisting}
# Get user supplied values
cascPath = './haarcascade_frontalface_default.xml'

# Create the haar cascade
faceCascade = cv2.CascadeClassifier(cascPath)
\end{lstlisting}

\begin{lstlisting}
# initialize the camera and grab a reference to the raw camera capture
camera = PiCamera()
camera.resolution = (160, 120)
camera.framerate = 32
rawCapture = PiRGBArray(camera, size=(160, 120))
\end{lstlisting}

\begin{lstlisting}
# allow the camera to warmup
time.sleep(0.1)
lastTime = time.time()*1000.0
# capture frames from the camera
for frame in camera.capture_continuous(rawCapture, format="bgr", use_video_port=True):
	# grab the raw NumPy array representing the image, then initialize the timestamp
	# and occupied/unoccupied text
    image = frame.array
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Detect faces in the image
    faces = faceCascade.detectMultiScale(
    gray,
    scaleFactor=1.1,
    minNeighbors=5,
    minSize=(30, 30),
    flags = cv2.cv.CV_HAAR_SCALE_IMAGE
    )
    print time.time()*1000.0-lastTime," Found {0} faces!".format(len(faces))
    lastTime = time.time()*1000.0

    # Draw a rectangle around the faces
    for (x, y, w, h) in faces:
        cv2.circle(image, (x+w/2, y+h/2), int((w+h)/3), (255, 255, 255), 1)
    # show the frame
    cv2.imshow("Frame", image)
    key = cv2.waitKey(1) & 0xFF
    if len(faces) == 1:
        print("Taking image...")
	camera.capture("foo.jpg")
	os.system('espeak "Human face detected"')
	inputImage= "./foo.jpg"
	del camera
	break 
	# clear the stream in preparation for the next frame
    rawCapture.truncate(0)
    
	# if the `q` key was pressed, break from the loop
    if key == ord("q"):
        del camera
        exit()
\end{lstlisting}


\subsection{Face Recognition}
\begin{lstlisting}
KAIROS = "api.kairos"
KairosGallery = 'MyFace'
KairosConfig = './kairos_config.json'
\end{lstlisting}

\begin{lstlisting}
def trainKairos(image, name):
    global KairosGallery
    headers = {
        'app_id': 'd39fc1b1',
        'app_key': '468d508d9463c8d24395926adabb1769'
    }
    data = {
        'image': base64.b64encode(image),
        'gallery_name': KairosGallery,
        'subject_id': name
    }
    r = requests.post('http://api.kairos.com/enroll', headers=headers, data=json.dumps(data))
    print(r.text)
    return(None)
\end{lstlisting}

\begin{lstlisting}
class Recognize():
    def __init__(self, API, config_file):
        self.api = API
        self.config = config_file

    #def recognize(self, image_path):
    #    return self.__recognizeKairos(image_path)
    
    def recognizeKairos(self, image):
        with open(image, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read())
        with open(self.config, "rb") as config_file:
            config = json.loads(config_file.read())
        data = {
            "image": encoded_string,
            "gallery_name": config["gallery_name"]
        }

        headers = {
            "Content-Type": "application/json",
            "app_id": config["app_id"],
            "app_key": config["app_key"]
        }
        try:
        r = requests.post("https://api.kairos.com/recognize", headers=headers, data=json.dumps(data))
        data = r.json()
    print data
    # print json.dumps(data, indent=4)
    faces = []
    if "images" in data:
        for obj in data["images"]:
            if obj["transaction"]["status"] == "success":
                face_obj = {}
                face_obj["person"] = obj["transaction"]["subject_id"]
                .decode("utf_8")
                #face_obj["faceid"] = obj["candidates"][0]["face_id"]
                .decode("utf_8")
                face_obj["confidence"] = obj["transaction"]["confidence"]
                faces.append(face_obj)
            elif obj["transaction"]["status"] == "failure":
                face_obj = {}
                face_obj["person"] = "unidentified"
                face_obj["confidence"] = 0
                faces.append(face_obj)
            else:
                print "its in last loop"
            return faces
        except requests.exceptions.RequestException as exception:
            print exception
        return None
\end{lstlisting}    

\begin{lstlisting}
if __name__ == "__main__":
    r = Recognize(KAIROS, "kairos_config.json")
    x = r.recognizeKairos(inputImage)
    
    #print x
    #print x["person"]
    #print x[0]["person"]
    string1 = x[0]["person"]
    #print string1
    os.system('espeak "Hello...""{}"'.format(string1))
    if x[0]["person"] == "unidentified":
        os.system('espeak "Please enter your name to Register"')
        nameToRegister = raw_input("Please enter your name to Register :")
        binaryData = open(inputImage, 'rb').read()
        print('Enrolling to Kairos')
        trainKairos(binaryData, nameToRegister)
        print "You are now Registered as :", nameToRegister
        os.system('espeak "Hello...""{}"'.format(nameToRegister))
        exit()
\end{lstlisting}

\subsection{Robot Car Navigation}
\begin{lstlisting}
import RPi.GPIO as GPIO
from time import sleep

GPIO.setmode(GPIO.BOARD)
\end{lstlisting}

\begin{lstlisting}
#Connecting two wheel motors to Raspberry Pi GPIO 
#Left Motor (Motor 1) connections
Motor1A = 16 #(GPIO 23 - Pin 16)
Motor1B = 18 #(GPIO 24 - Pin 18)
Motor1Enable = 22 #(GPIO 25 - Pin 22)

#Right Motor (Motor 2) Connecctions
Motor2A = 21 #(GPIO 9 - Pin 21)
Motor2B = 19 #(GPIO 10 - Pin 19)
Motor2Enable = 23 #(GPIO 11 - Pin 23)
\end{lstlisting}

\begin{lstlisting}
#Ouptut of Morors to set as OUT
GPIO.setup(Motor1A,GPIO.OUT)
GPIO.setup(Motor1B,GPIO.OUT)
GPIO.setup(Motor1Enable,GPIO.OUT)
GPIO.setup(Motor2A,GPIO.OUT)
GPIO.setup(Motor2B,GPIO.OUT)
GPIO.setup(Motor2Enable,GPIO.OUT)

\end{lstlisting}

\begin{lstlisting}
# Defining function for Robot car to move forward
def forward():
	GPIO.output(Motor1A,GPIO.HIGH)
	GPIO.output(Motor1B,GPIO.LOW)
	GPIO.output(Motor1Enable,GPIO.HIGH) 
	GPIO.output(Motor2A,GPIO.HIGH)
	GPIO.output(Motor2B,GPIO.LOW)
	GPIO.output(Motor2Enable,GPIO.HIGH) 

	sleep(2)
\end{lstlisting}

\begin{lstlisting}
# Defining function for Robot car to move backward
def backward():
	GPIO.output(Motor1A,GPIO.LOW)
	GPIO.output(Motor1B,GPIO.HIGH)
	GPIO.output(Motor1Enable,GPIO.HIGH)
	GPIO.output(Motor2A,GPIO.LOW)
	GPIO.output(Motor2B,GPIO.HIGH)
	GPIO.output(Motor2Enable,GPIO.HIGH)

	sleep(2)
\end{lstlisting}

\begin{lstlisting}
# Defining function for Robot car to turn right
def turnRight():
	print("Going Right")
	GPIO.output(Motor1A,GPIO.HIGH)
	GPIO.output(Motor1B,GPIO.LOW)
	GPIO.output(Motor1Enable,GPIO.HIGH)
	GPIO.output(Motor2A,GPIO.LOW)
	GPIO.output(Motor2B,GPIO.LOW)
	GPIO.output(Motor2Enable,GPIO.LOW)

	sleep(2)
\end{lstlisting}

\begin{lstlisting}
# Defining function for Robot car to turn left
def turnLeft():
	print("Going Left")
	GPIO.output(Motor1A,GPIO.LOW)
	GPIO.output(Motor1B,GPIO.LOW)
	GPIO.output(Motor1Enable,GPIO.LOW)
	GPIO.output(Motor2A,GPIO.HIGH)
	GPIO.output(Motor2B,GPIO.LOW)
	GPIO.output(Motor2Enable,GPIO.HIGH)

	sleep(2)
\end{lstlisting}

\begin{lstlisting}
# Defining function for Robot car to stop
def stop():
	print("Stopping")
	GPIO.output(Motor1A,GPIO.LOW)
	GPIO.output(Motor1B,GPIO.LOW)
	GPIO.output(Motor1Enable,GPIO.LOW)
	GPIO.output(Motor2A,GPIO.LOW)
	GPIO.output(Motor2B,GPIO.LOW)
	GPIO.output(Motor2Enable,GPIO.LOW)
\end{lstlisting}

\subsection{Controling Robot Car using webserver}
\begin{lstlisting}
from flask import Flask, render_template, request, redirect, url_for, make_response
import RPi.GPIO as GPIO
import motors

#set up GPIO
GPIO.setmode(GPIO.BOARD) 

#set up flask server
app = Flask(__name__) 

#when the root IP is selected, return index.html page
@app.route('/')
def index():

	return render_template('index.html')
\end{lstlisting}

\begin{lstlisting}
#recieve which pin to change from the button press on index.html
#each button returns a number that triggers a command in this function
#
#Uses methods from motors.py to send commands to the GPIO to operate the motors
@app.route('/<changepin>', methods=['POST'])
def reroute(changepin):

	changePin = int(changepin) #cast changepin to an int

	if changePin == 1:
		motors.turnLeft()
	elif changePin == 2:
		motors.forward()
	elif changePin == 3:
		motors.turnRight()
	elif changePin == 4:
		motors.backward()
	else:
		motors.stop()


	response = make_response(redirect(url_for('index')))
	return(response)

#set up the server in debug mode to the port 8000
app.run(debug=True, host='0.0.0.0', port=8000) 
\end{lstlisting}

\section{Application}
There are lots of applications of face recognition. Face recognition is already being used to unlock phones and specific applications. Face recognition is also used for biometric surveillance. Banks, retail stores, stadiums, airports and other facilities use facial recognition to reduce crime and prevent violence.

\section{Conclusion}


\begin{acks}

The authors would like to thank Dr. Gregor von Laszewski for his support and suggestions in writing this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\end{document}
